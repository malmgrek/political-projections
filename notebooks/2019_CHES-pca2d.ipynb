{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from dimred.datasets import ches2019\n",
    "from dimred import analysis, plot\n",
    "\n",
    "from sklearn import decomposition, impute, preprocessing\n",
    "from sklearn.experimental import enable_iterative_imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load dataset\n",
    "#\n",
    "(X_train, features) = ches2019.prepare(\n",
    "    ches2019.cleanup(\n",
    "        # ches2019.update(),\n",
    "        ches2019.load(),\n",
    "        nan_floor_row=0.9,\n",
    "        nan_floor_col=0.75\n",
    "    )\n",
    ")\n",
    "\n",
    "# Scaling to reasonable units\n",
    "scaler = analysis.IntervalScaler([\n",
    "    v for (k, v) in ches2019.feature_scales.items() if k in features\n",
    "])\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = impute.IterativeImputer().fit(X_train)\n",
    "X_train = imputer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_linkage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "\n",
    "corr = spearmanr(X_train).correlation\n",
    "corr_linkage = hierarchy.ward(corr)\n",
    "dendro = hierarchy.dendrogram(\n",
    "    corr_linkage, labels=features, ax=ax1, leaf_rotation=90\n",
    ")\n",
    "dendro_idx = np.arange(0, len(dendro[\"ivl\"]))\n",
    "\n",
    "ax2.imshow(corr[dendro['leaves'], :][:, dendro['leaves']])\n",
    "ax2.set_xticks(dendro_idx)\n",
    "ax2.set_yticks(dendro_idx)\n",
    "ax2.set_xticklabels(dendro['ivl'], rotation='vertical')\n",
    "ax2.set_yticklabels(dendro['ivl'])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = plot.plot_training_data(\n",
    "    fig.gca(),\n",
    "    X_train,\n",
    "    features,\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"cubehelix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Fit decpomposition\n",
    "#\n",
    "\n",
    "# Principal component analysis\n",
    "decomposer = decomposition.PCA(2).fit(X_train)\n",
    "\n",
    "Y = decomposer.transform(X_train)\n",
    "Y_2d = Y[:, :2]\n",
    "\n",
    "U = decomposer.components_ \n",
    "V = scaler.inverse_transform(U)\n",
    "\n",
    "(fig, ax) = plt.subplots(figsize=(6, 8))\n",
    "ax = plot.plot_components(ax, V[:2], features)\n",
    "_ = ax.set_title(\n",
    "    ax.get_title() + \"\\n Explained variance ratio {}\".format(\n",
    "        decomposer.explained_variance_ratio_[:2].sum()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Estimating the 2d probability density\n",
    "# \n",
    "\n",
    "# Fit KDE and sample\n",
    "kde = analysis.fit_kde(Y_2d)\n",
    "num_samples = 10\n",
    "Y_samples = kde.sample(num_samples)\n",
    "sample_colors = plot.create_colors(\n",
    "    num_samples, plt.cm.gist_rainbow\n",
    ")  # for plotting\n",
    "\n",
    "# Evaluate probability density in grid for plotting\n",
    "(x, y, density, xlim, ylim) = analysis.score_density_grid(kde=kde, Y=Y_2d, num=100)\n",
    "\n",
    "\n",
    "#\n",
    "# Plot\n",
    "#\n",
    "\n",
    "(fig, axs) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.contourf(x, y, density, levels=10, cmap=plt.cm.cubehelix, alpha=0.9)\n",
    "ax.set_title(\"Estimated probability density\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.scatter(*Y_2d.T, alpha=0.5, c=\"k\")\n",
    "_ = ax.set_xlim(xlim)\n",
    "_ = ax.set_ylim(ylim)\n",
    "ax.set_title(\"Projected observations\")\n",
    "\n",
    "(fig, ax) = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(*Y_samples.T, c=sample_colors, s=100)\n",
    "ax.contour(x, y, density, levels=10, cmap=\"cubehelix\")\n",
    "ax.grid(True)\n",
    "_ = ax.set_xlim(xlim)\n",
    "_ = ax.set_ylim(ylim)\n",
    "ax.set_title(\"Random samples from estimated distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Mapping back to original dimensions\n",
    "#\n",
    "\n",
    "X_samples = scaler.inverse_transform(\n",
    "    decomposer.inverse_transform(Y_samples)\n",
    ")\n",
    "\n",
    "(fig, ax) = plt.subplots(figsize=(8, 8))\n",
    "ax = plot.plot_components(\n",
    "    ax, \n",
    "    X_samples, \n",
    "    features, \n",
    "    label=\"Sample\",\n",
    "    colors=sample_colors\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
